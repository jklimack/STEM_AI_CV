{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd5192f2",
   "metadata": {},
   "source": [
    "# Computer Vision Demo Project\n",
    "\n",
    "In this project you will take a look at the steps involved in performing specific computer vision tasks such as:\n",
    "- Color Accents\n",
    "- Edge Detection\n",
    "- Object Detection / Classification\n",
    "- Object Segmentation\n",
    "\n",
    "The code for the project has already been written, so you mainly just need to run each block. \n",
    "\n",
    "To run a block of code press SHIFT+ENTER on the keyboard while it is selected. \n",
    "\n",
    "If you run into any major problems talking about the KERNEL, then at the top of the web page there is a button called Kernel which you then need to click the RESTART AND CLEAR OUTPUT button. \n",
    "\n",
    "You will then need to re-run any important blocks for the task. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89620909",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT RUN THIS BLOCK! \n",
    "\n",
    "# necessary installs\n",
    "!pip install ultralytics\n",
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd21c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imported packages\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "from skimage import io, feature\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.filters import gaussian\n",
    "from skimage.segmentation import chan_vese, active_contour, watershed, checkerboard_level_set, felzenszwalb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a05aee",
   "metadata": {},
   "source": [
    "# Task 1: COLOR ACCENT\n",
    "\n",
    "For this exercise you will create a color accent for an image. That is, given an image, convert the entire image to black and white EXCEPT for a specific color, which is provided in RGB (Red, Green, Blue) form. You will be modifying the actual pixel values of the image to apply this color change. \n",
    "\n",
    "Here is a list of steps involved that you will follow to perform this task:\n",
    "1. Load the image\n",
    "2. Create a black and white version of the image\n",
    "3. Choose which color you wish to select\n",
    "4. Create a \"selection mask\". This highlights where the pixels in the image of the selected color are located. \n",
    "5. Using the mask, create a new image that is black and white with the selected color still being present\n",
    "6. Display the four main steps all at once to show the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efab89b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the image\n",
    "orig_img_file = \"traffic.jpg\"\n",
    "\n",
    "orig_img = io.imread(orig_img_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ecccf3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the image\n",
    "plt.figure(figsize=(20, 6))\n",
    "plt.imshow(orig_img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ea1ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the size of the image (resolution and number of colors)\n",
    "print(\"Shape: \", orig_img.shape)\n",
    "print()\n",
    "\n",
    "# display the RGB pixel values of the image\n",
    "print(orig_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64cfa5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the grayscale image\n",
    "# multiply by 255 to change the range from [0,1] to [0,255]\n",
    "gray_img = rgb2gray(orig_img) * 255\n",
    "\n",
    "# convert to int (integer instead of decimal number)\n",
    "gray_img = np.array(gray_img, dtype='int')\n",
    "\n",
    "# display the black and white image\n",
    "plt.figure(figsize=(20, 6))\n",
    "plt.imshow(gray_img, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c08b363",
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the grayscale values\n",
    "# brightness level\n",
    "print(\"Shape: \", gray_img.shape)\n",
    "print()\n",
    "print(gray_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dbb4e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose a color you wish to highlight\n",
    "color_selection = [255, 0, 0]\n",
    "\n",
    "# select a tolerance for deciding how close pixel values need to be to be considered the same\n",
    "tolerance = 160\n",
    "\n",
    "# subtract the selection color from EVERY pixel in the image\n",
    "selection_matrix = (orig_img - color_selection) ** 2\n",
    "\n",
    "# create a mask indicating where the pixels are located\n",
    "selection_mask = np.zeros(gray_img.shape, dtype='int')\n",
    "selection_mask[:,:] = (selection_matrix[:,:,0] + selection_matrix[:,:,1] + selection_matrix[:,:,2]) ** (1/2) < tolerance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b777d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the selection mask\n",
    "plt.figure(figsize=(20, 6))\n",
    "plt.imshow(selection_mask, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6889b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "color_selected_img = np.zeros(orig_img.shape, dtype='int')\n",
    "\n",
    "x = gray_img[:,:] * ((selection_mask - 1) * -1)\n",
    "\n",
    "color_selected_img[:,:,0] = x + orig_img[:,:, 0] * selection_mask\n",
    "color_selected_img[:,:,1] = x + orig_img[:,:, 1] * selection_mask\n",
    "color_selected_img[:,:,2] = x + orig_img[:,:, 2] * selection_mask\n",
    "\n",
    "plt.figure(figsize=(20, 6))\n",
    "plt.imshow(color_selected_img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493ccba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the four main steps of the task\n",
    "\n",
    "fig, axs = plt.subplots(2,2, figsize=(15, 10))\n",
    "\n",
    "axs[0,0].imshow(orig_img)\n",
    "axs[0,0].set_title(\"Original Image\")\n",
    "axs[0,1].imshow(gray_img, cmap='gray')\n",
    "axs[0,1].set_title(\"Black and White Image\")\n",
    "axs[1,0].imshow(selection_mask, cmap='gray')\n",
    "axs[1,0].set_title(\"Selection Mask: where is the selected color? \")\n",
    "axs[1,1].imshow(color_selected_img)\n",
    "axs[1,1].set_title(\"Final Image\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117cd09f",
   "metadata": {},
   "source": [
    "# Task 2: EDGE DETECTION\n",
    "\n",
    "Edge detection is the process of locating all of the edges within an image. Basically, it searches for the pixels in the image where there is a drastic change in pixel instensity (eg. pixel 1 is bright, pixel 2 is dark, thus there is a change resulting in an edge). \n",
    "\n",
    "Steps to follow:\n",
    "1. Load an image\n",
    "2. Convert image to black and white. We only need to care about the intensity (brightness) of the pixels, not the actual color. \n",
    "3. Compute the edges of the image\n",
    "4. Add a blur to the image. This step reduces the clarity of the edges on the image. \n",
    "5. recompute edges on blurred image\n",
    "6. Look at the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8147b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load image\n",
    "orig_img_2 = \"butterfly.jpg\"\n",
    "\n",
    "orig_img_2 = io.imread(orig_img_2)\n",
    "\n",
    "# display the image\n",
    "plt.figure(figsize=(20, 6))\n",
    "plt.imshow(orig_img_2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704b5184",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the image to black and white\n",
    "# colors are not necessary to find the edges\n",
    "gray_img_2 = rgb2gray(orig_img_2)\n",
    "\n",
    "# display the image\n",
    "plt.figure(figsize=(20, 6))\n",
    "plt.imshow(gray_img_2, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f094c17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the edge locations\n",
    "edges_1 = feature.canny(gray_img_2)\n",
    "\n",
    "# display the edges\n",
    "plt.figure(figsize=(20, 6))\n",
    "plt.imshow(edges_1, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8afd76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a blur to the image\n",
    "# set blur amount\n",
    "blur = 2\n",
    "\n",
    "blurred_img = gaussian(gray_img_2, sigma=blur)\n",
    "\n",
    "# display the edges\n",
    "plt.figure(figsize=(20, 6))\n",
    "plt.imshow(blurred_img, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb59bf7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the edge locations\n",
    "edges_2 = feature.canny(blurred_img)\n",
    "\n",
    "# display the edges\n",
    "plt.figure(figsize=(20, 6))\n",
    "plt.imshow(edges_2, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6396277",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final results\n",
    "\n",
    "fig, axs = plt.subplots(2,2, figsize=(15, 10))\n",
    "\n",
    "\n",
    "axs[0,0].imshow(gray_img_2, cmap='gray')\n",
    "axs[0,0].set_title(\"Original Black and White Image\")\n",
    "axs[0,1].imshow(edges_1, cmap='gray')\n",
    "axs[0,1].set_title(\"Edges 1\")\n",
    "axs[1,0].imshow(blurred_img, cmap='gray')\n",
    "axs[1,0].set_title(\"Blurred Image\")\n",
    "axs[1,1].imshow(edges_2, cmap='gray')\n",
    "axs[1,1].set_title(\"Edges 2\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8419a7d7",
   "metadata": {},
   "source": [
    "# Task 3: OBJECT DETECTION, CLASSIFICATION AND SEGMENTATION\n",
    "\n",
    "Object detection and classification are two of the most important computer vision tasks to date, as this task gets a machine to identify the location and type of objects in an image. For example, labelling the different objects in a traffic scene as person, car, street light, stop sign, etc. \n",
    "\n",
    "This is the main area where Artificial Intelligence and Computer Vision merge. \n",
    "\n",
    "Remember, a computer only knows numbers, it can't actually \"see\" objects as humans do. Therefore, how can a machine know what object(s) are being shown in an image? \n",
    "\n",
    "We first have to \"teach\" the computer what the objects are by showing it thousands of example images of that object. Then it can learn the pattern of numbers that identifies an object as being a \"cat\" (for example). \n",
    "\n",
    "For this task, we will use a pre-trained AI to identify and label objects in a scene. We use a pre-trained AI as sometimes it takes hours, days, or even weeks to properly train a machine from scratch to perform high-end tasks. \n",
    "\n",
    "The name of the AI model we will use is called \"YOLO\". YOLO was trained using images from the dataset called COCO. \n",
    "\n",
    "Object Detection: Locating objects in a scene and placing a bounding box around each object. \n",
    "\n",
    "Object Classification: Adding a label to each object so that the machine knows what the object is (is it a cat or a dog?). \n",
    "\n",
    "Object Segmentation: Finding the exact pixels that are relevant to each specific object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ddace6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# additional imports and configurations\n",
    "from skimage import io\n",
    "from skimage.transform import resize\n",
    "from ultralytics import YOLO\n",
    "\n",
    "import cv2\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "matplotlib.use('tkAgg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7e362d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the image\n",
    "orig_img_3_file = \"desk.jpg\"\n",
    "img_3 = io.imread(orig_img_3_file)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(img_3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0b5acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the size of the image (resolution) so that it fits on the screen better\n",
    "scalex = 800 / img_3.shape[0]\n",
    "\n",
    "img_3 = resize(img_3, (img_3.shape[0] * scalex, img_3.shape[1] * scalex))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dcbc558",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the resized image to the computer\n",
    "resized_file = \"resized_image.jpg\"\n",
    "io.imsave(resized_file, img_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8e0ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL \n",
    "\n",
    "# object detection\n",
    "model = YOLO('yolov8n.pt')\n",
    "\n",
    "# object segmentation\n",
    "#model = YOLO('yolov8x-seg.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359ab79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model(resized_file, show=True, save=True)\n",
    "\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f81d874",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
